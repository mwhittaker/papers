<!DOCTYPE html>
<html>
<head>
  <title>Papers</title>
  <link href='../style.css' rel='stylesheet'>
  <meta name=viewport content="width=device-width, initial-scale=1">
</head>

<body>
  <div id="container">
<h1 id="datalog-and-recursive-query-processing-2013"><a href="https://scholar.google.com/scholar?cluster=11160406363745186504&amp;hl=en&amp;as_sdt=0,5">Datalog and Recursive Query Processing (2013)</a></h1>
<p>Datalog's popularity peaked in the 1980s and 1990s before its hype dwindled. Recently however, Datalog has been making a comeback, showing up in bigger and badder applications in both academia and industry. This book surveys the syntax, semantics, evaluation, extensions, and applications of Datalog.</p>
<h2 id="a-first-example">A First Example</h2>
<p>Let <code>link</code> be a binary relation where <code>(X, Y)</code> is in <code>link</code> (denoted <code>link(X, Y)</code>) if there is a <em>link</em> from <code>X</code> to <code>Y</code>. The following Datalog program computes a binary relation <code>reachable</code> where <code>reachable(X, Y)</code> if there is a <em>path</em> from <code>X</code> to <code>Y</code>.</p>
<pre><code>r1: reachable(X, Y) :- link(X, Y)
r2: reachable(X, Y) :- link(X, Z), reachable(Z, Y)</code></pre>
<p>The program consists of two rules, <code>r1</code> and <code>r2</code>. Notably, <code>r2</code> is a <strong>recursive</strong> rule. In fact it is a <strong>linear recursive</strong> rules.</p>
<p>To evaluate the program, we can begin with <code>reachable</code> empty. Then, we repeatedly use the rules in the program to compute new tuples that belong in <code>reachable</code>. We repeat these iterations to a fixpoint. This is known as <strong>naive evaluation</strong>.</p>
<p>A slightly more sophisticated approach would not re-evaluate a rule like <code>link(X, Z), reachable(Z, Y)</code> if <code>X</code>, <code>Y</code>, and <code>Z</code> were already in <code>link</code> and <code>reachable</code> in a previous iteration. That is, we do not want to redundantly recompute facts we already know. This corresponds loosely to <strong>semi-naive evaluation</strong>.</p>
<p>Both of these approaches are <strong>bottom-up</strong> (also known as <strong>forward chaining</strong>). Prolog, on the other hand, begins with a query and works backwards finding derivations. This <strong>top-down</strong> approach (also known as <strong>backwards chaining</strong>) does not compute irrelevant facts. Bottom-up approaches can be optimized so that they also do not compute irrelevant facts.</p>
<h2 id="language">Language</h2>
<p>A Datalog program is composed of a set of rules of the form <code>A :- B1, ..., Bn</code> where <code>A</code> is the <strong>head</strong> and <code>B1, ..., Bn</code> is the <strong>body</strong>. A couple of definitions:</p>
<ul>
<li>A <strong>term</strong> (e.g. <code>X</code>) is a constant or variable.</li>
<li>Things like <code>link</code> or <code>reachable</code> are <strong>predicate symbols</strong> or <strong>functions</strong>.</li>
<li>An <strong>atom</strong> (or <strong>goal</strong>) is a predicate symbol with terms as arguments (e.g. <code>link(X, Y)</code>).</li>
<li>An atom with constant arguments is a <strong>ground atom</strong>.</li>
<li>Predicate symbols are either <strong>extensional database</strong> (EDB) predicates if they belong to a base table or are <strong>intensional database</strong> (IDB) predicates if they are derived by a Datalog program.</li>
<li>A <strong>database instance</strong> is a set of ground instances.</li>
<li>A <strong>source database instance</strong> is a database instance in which all atoms are from EDB predicates.</li>
<li>The <strong>active domain</strong> is the set of all constants in a database.</li>
<li>The <strong>Herbrand base</strong> of a Datalog program <code>P</code>, denoted <code>B(P)</code>, is the set of all atoms (EDB or IDB) in computed by <code>P</code>.</li>
<li>A <strong>fact rule</strong> is a rule with an empty body and with no free variables appearing in the head.</li>
<li>A <strong>ground instance</strong> of a rule is the rule in which all variables are replaced with constants.</li>
</ul>
<p>Finally, the <strong>range restriction property</strong> says that all variables in the head of a rule must appear in the body of the rule.</p>
<h2 id="model-theoretic-semantics">Model-Theoretic Semantics</h2>
<p>There are three equivalent semantics for core Datalog. The first is the model-theoretic semantics. In the model theoretic semantics, rules like <code>reachable(X, Y) :- reachable(X, Z), link(Z, Y)</code> are viewed as constraints <code>forall X, forall Y, forall Z. reachable(X, Z) and link(Z, Y) ==&gt; reachable(X, Y)</code>. A <strong>model</strong> of a source database instance <code>I</code> and Datalog program <code>P</code> is a superset <code>I'</code> of <code>I</code> that satisfies all the constraints.</p>
<p>There always exists a unique minimal model which we denote <code>P(I)</code> and the size of <code>P(I)</code> is polynomial with respect to the size of <code>I</code>. This result follows from the following two findings:</p>
<ol style="list-style-type: decimal">
<li>Consider the database instance <code>I'</code> that we get if we let <code>R(x1, ..., xn)</code> be in <code>I'</code> for every IDB predicate <code>R</code> and every constants <code>x1</code>, ..., <code>xn</code> in the active domain. <code>I'</code> is a model. The size of <code>I'</code> is polynomial with respect to the size of the active domain. The degree of the polynomial is the largest predicate arity in <code>I</code>.</li>
<li>The intersection of any two models is a model.</li>
</ol>
<p>Assume for contradiction there did not exist a unique minimal model. 2 tells us that we can intersect any two minimal models to get a smaller model, violating our assumption that they were unique. Since there exists a unique minimal model, either <code>I'</code> from 1 is the unique minimal model, or the minimal model is smaller than it. This implies that the unique minimal model is at worst polynomial in the size of <code>I</code>.</p>
<h2 id="fixpoint-theoretic-semantics">Fixpoint-Theoretic Semantics</h2>
<p>An atom <code>A</code> is an <strong>immediate consequence</strong> of program <code>P</code> and database instance <code>I</code> if either</p>
<ol style="list-style-type: decimal">
<li><code>A</code> is a ground atom in an EDB predicate of <code>I</code> or</li>
<li><code>A :- B1, ..., Bn</code> is a ground instance of a rule in <code>P</code>.</li>
</ol>
<p>The <strong>immediate consequence operator</strong> <code>T_P</code> maps database instance <code>I</code> to the set of all atoms <code>A</code> such that <code>A</code> is an immediate consequence of <code>P</code> and <code>I</code>. For any <code>P</code> and any <code>I</code>, there exists a unique least fixpoint <code>I</code> (i.e. <code>T_P(I) = I</code>) and <code>I = P(I)</code>. That is, the least fixpoint of <code>T_P</code> is equivalent to the unique minimal model.</p>
<p>Repeatedly applying the immediate consequence operator produces the least fixpoint it a polynomial number of steps. Each application of the operator takes a polynomial amount of time. Thus, computing the least fixpoint takes a polynomial amount of time.</p>
<h2 id="proof-theoretic-semantics">Proof-Theoretic Semantics</h2>
<p>We can also view the meaning of a Datalog program <code>P</code> and source database instance <code>I</code> as the set of all ground atoms provable using the ground atoms in <code>I</code> as axioms and the rules in <code>P</code> as inference rules.</p>
<h2 id="negation">Negation</h2>
<p>All core Datalog programs are monotone (this is best understood with the proof-theoretic semantics). That is, for any Datalog program <code>P</code> and pair of source database instances <code>I</code> and <code>J</code>, if <code>I</code> is a subset of <code>J</code>, then <code>P(I)</code> is a subset of <code>P(J)</code>. This means that core Datalog programs cannot compute non-monotone queries. For example, we cannot compute a predicate <code>unreachable(X, Y)</code> showing when a node <code>Y</code> is unreachable from a node <code>X</code>. We can compute such a predicate if we have negation</p>
<pre><code>reachable(X, Y) :- link(X, Y)
reachable(X, Y) :- link(X, Z), reachable(Z, Y)
node(X) :- link(X, _)
node(Y) :- link(_, Y)
unreachable(X, Y) :- node(X), node(Y), not reachable(X, Y)</code></pre>
<p>but unfettered negation can lead to some nonsensical programs:</p>
<pre><code>p :- not q
q :- not p</code></pre>
<p>Here, both <code>{p}</code> and <code>{q}</code> are minimal models and minimal fixpoints of <code>P</code>, but neither is unique. Moreover, using the proof-theoretic semantics, neither <code>p</code> nor <code>q</code> can be proved. To avoid these nonsensical programs, we have to restrict the use of negation in Datalog programs. We first look at <strong>semipositive Datalog with negation</strong> and then <strong>stratified Datalog with negation</strong>.</p>
<h2 id="semipositive-datalog-with-negation">Semipositive Datalog with Negation</h2>
<p>In semipositive Datalog with negation, negation can only appear on an EDB atom. For example, we can negate <code>link(X, Y)</code> but not <code>reachable(X, Y)</code>. Moreover, any variable that appears in the head of a rule must appear in a non-negated atom in the body of the rule. If we had a rule like this <code>p(X) :- not q(X)</code> then a minimal model could be infinite and depend on values outside of the source database instance.</p>
<p>The semantics of semipositive Datalog with negation are straightforward. Both the model-theoretic and fixpoint-theoretic semantics carry over nicely, though the proof-theoretic semantics do not. As with core Datalog, a least fixpoint of a semipositive Datalog program can be always be found in polynomial time.</p>
<h2 id="stratified-datalog-with-negation">Stratified Datalog with Negation</h2>
<p>A <strong>stratification</strong> of Datalog program <code>P</code> is an ordered partition <code>P1, ..., Pn</code> of the IDB predicates in <code>P</code> where</p>
<ol style="list-style-type: decimal">
<li>If <code>A :- ..., B, ...</code> appears in <code>P</code>, <code>A</code> belongs to <code>Pi</code>, and <code>B</code> belongs to <code>Pj</code>, then <code>i &gt;= j</code>. Intuitively, <code>A</code> can belong to the same strata as <code>B</code> or a future one.</li>
<li>If <code>A :- ..., not B, ...</code> appears in <code>P</code>, <code>A</code> belongs to <code>Pi</code>, and <code>B</code> belongs to <code>Pj</code>, then <code>i &gt; j</code>. Intuitively, <code>A</code> must belong to a future strata than <code>B</code>.</li>
</ol>
<p>A Datalog program <code>P</code> is <strong>stratifiable</strong> if there exists a stratification of <code>P</code>. Given a stratification of <code>P</code>, we can run each strata in turn as a semipositive Datalog with negation program. After each strata is run, its IDB predicates become EDB predicates for the next strata. It turns out that all stratifications produce the same result.</p>
<p>We can determine if a program is stratifiable and find a stratification using a precedence graph. Each IDB predicate becomes a vertex and</p>
<ol style="list-style-type: decimal">
<li>If <code>A :- ..., B, ...</code> appears in the program, then there is an edge from <code>B</code> to <code>A</code>.</li>
<li>If <code>A :- ..., not B, ...</code> appears in the program, then there is an edge from <code>B</code> to <code>A</code> labelled with a negation.</li>
</ol>
<p>If the precedence graph is free of cycles in which one edge of the cycle is labelled with a negation, then the program is stratifiable. Each strongly connected component of the graph becomes a strata and a topological sort of the strata orders them. Using a neat algorithm, all of this can be done in linear time with respect to the number of IDB predicates. Stratifiable Datalog programs with negation can be run in polynomial time.</p>
<p>The <strong>Immerman-Vardi theorem</strong> says that any query that can be computed in polynomial time can be expressed by a stratifiable Datalog program with negation. We've also seen that every stratifiable Datalog program with negation can be run in polynomial time. This means that stratifiable Datalog with negation programs capture exactly the queries that can be computed in polynomial time. Note however that the term &quot;query&quot; is very technical and also assumes that the active domain is ordered.</p>
<h2 id="aggregation">Aggregation</h2>
<p>Stratifiable Datalog programs with negation cannot compute aggregates (e.g. <code>count</code>, <code>sum</code>, <code>max</code>, <code>min</code>, <code>average</code>) which might come in handy. For example, we cannot compute the number of nodes reachable from a node <code>X</code>:</p>
<pre><code>reachable(X, Y) :- link(X, Y)
reachable(X, Y) :- link(X, Z), reachable(Z, Y)
summary(X, count&lt;Y&gt;) :- reachable(X, Y)</code></pre>
<p>An <strong>aggregate function</strong> maps bags of values to a single value. An <strong>aggregate term</strong> is an expression <code>f&lt;t1, ..., tk&gt;</code> where <code>f</code> is an <strong>aggregate function sumbol</strong> of arity <code>k</code> and <code>t1</code> to <code>tk</code> are ordinary terms. We also augment the range restriction property with a new clause:</p>
<ul>
<li>If a variable <code>X</code> appears in an aggregate term in the head of a rule, it cannot appear in the head of a rule outside an aggregate term.</li>
</ul>
<p>The head variables that do not appear in an aggregate term are known as <strong>grouping variables</strong>. The meaning of a aggregate in Datalog is pretty much the same as a GROUP BY in SQL. For example, the Datalog</p>
<pre><code>sales_by_product(Product, sum&lt;Sales&gt;) :- sales(Product, City, Sales)</code></pre>
<p>is equivalent to the SQL</p>
<pre><code>SELECT   S.Product, SUM(S.Sales)
FROM     Sales S
GROUP BY S.Product;</code></pre>
<p>Like with negation, unfettered aggregation can lead to some wonky programs:</p>
<pre><code>p(X) :- q(X)
p(sum&lt;X&gt;) :- p(X)</code></pre>
<p>Here, if <code>q(1)</code> and <code>q(2)</code>, then we use the first two rules to derive <code>p(1)</code> and <code>p(2)</code>. Then, we use the third rule to deduce <code>p(3)</code>. But then we have to deduce <code>p(6)</code> and <code>p(12)</code> and so on <em>ad infinitum</em>.</p>
<p>Like with negation, we can avoid this nonsense with stratification. A stratification of a Datalog program <code>P</code> with both aggregation and negation is an ordered partition of the IDB predicates in <code>P</code> such that:</p>
<ol style="list-style-type: decimal">
<li>If <code>A :- ..., B, ...</code> appears in <code>P</code>, <code>A</code> belongs to <code>Pi</code>, and <code>B</code> belongs to <code>Pj</code>, then <code>i &gt;= j</code>. Intuitively, <code>A</code> can belong to the same strata as <code>B</code> or a future one.</li>
<li>If <code>A :- ..., not B, ...</code> appears in <code>P</code>, <code>A</code> belongs to <code>Pi</code>, and <code>B</code> belongs to <code>Pj</code>, then <code>i &gt; j</code>. Intuitively, <code>A</code> must belong to a future strata than <code>B</code>.</li>
<li>If <code>A :- ..., B, ...</code> appears in <code>P</code>, <code>A</code> includes an aggregate term and belongs to <code>Pi</code>, and <code>B</code> belongs to <code>Pj</code>, then <code>i &gt; j</code>.</li>
</ol>
<p>We can modify the precedence graph algorithm from before. We introduce an edge from <code>B</code> to <code>A</code> labelled with an aggregation if <code>A :- ..., B, ...</code> and <code>A</code> includes an aggregate. There exists a stratification if there does not exist any cycles with either an aggregate or negation edge.</p>
<p>We can update the immediate consequence operator to handle aggregation and then the fixpoint-theoretic semantics carry over. Model-theoretic semantics also carry over nicely.</p>
<p>Finally, there are a number of optimizations we can do to avoid computing unnecessary parts of an aggregation. See the paper for an example with computing shortest paths.</p>
<h2 id="bottom-up-evaluation">Bottom-up Evaluation</h2>
<p>We can evaluate a Datalog program using the <strong>naive method</strong>. We repeatedly apply the immediate consequence operator in a series of iterations until we reach a fixpoint. As we noted earlier, the naive method redundantly derives tuples.</p>
<p>The <strong>seminaive method</strong> avoids re-deriving tuples by only performing derivations with freshly derived tuples (called <strong>deltas</strong>). We assume each rule is of the form</p>
<pre><code>p :- p_1, ..., pn, q1, ..., qm</code></pre>
<p>where the <code>p</code>s are mutually recursive and the <code>q</code>s are EDB predicates. Let <code>p[i]</code> denote the tuples at the beginning of the <code>i</code>th round (note <code>p[0] = {}</code>). Let <code>d(p)[i]</code> be the fresh tuples generated in round <code>i</code>. Note that <code>p[i+1] = p[i] + d(p)[i]</code>. Using this notation, we can rewrite rules of the form above into a new set of rules which will compute <code>D(p)[i]</code>: an over-approximation of <code>d(p)[i]</code>. For simplicity, we illustrate using a simple rule:</p>
<pre><code>$$
\newcommand{\ud}{\texttt{:-}}
\begin{align}
    p^{[i+1]} &amp;\ud{}\ a^{[i]}, b^{[i]} \\
              &amp;= (a^{[i-1]} + \delta(a)^{[i-1]}),
                 (b^{[i-1]} + \delta(b)^{[i-1]}) \\
              &amp;= (a^{[i-1]}, b^{[i-1]}) +
                 (\delta(a)^{[i-1]}, b^{[i-1]}) +
                 (a^{[i-1]}, \delta(b)^{[i-1]}) +
                 (\delta(a)^{[i-1]}, \delta(b)^{[i-1]}) \\
              &amp;= (a^{[i-1]}, b^{[i-1]}) +
                 (\delta(a)^{[i-1]}, b^{[i-1]}) +
                 (a^{[i]}, \delta(b)^{[i-1]})
\end{align}
$$</code></pre>
<p>In general, we can rewrite a rule <code>p :- p1, ..., pn</code> into the following:</p>
<pre><code>$$
\begin{array}{lllllll}
\Delta(p)^{[i]}
  &amp; \ud{}
  &amp; \delta(p_1)^{[i-1]},
  &amp; p_2^{[i-1]},
  &amp; p_3^{[i-1]},
  &amp; \ldots
  &amp; p_n^{[i-1]} \\
\Delta(p)^{[i]}
  &amp; \ud{}
  &amp; p_1^{[i]},
  &amp; \delta(p_2)^{[i-1]},
  &amp; p_3^{[i-1]},
  &amp; \ldots,
  &amp; p_n^{[i-1]} \\
\Delta(p)^{[i]}
  &amp; \ud{}
  &amp; p_1^{[i]},
  &amp; p_2^{[i]},
  &amp; \delta(p_3)^{[i-1]},
  &amp; \ldots,
  &amp; p_n^{[i-1]} \\
\ldots &amp; &amp; &amp; &amp; &amp; &amp; \\
\Delta(p)^{[i]}
  &amp; \ud{}
  &amp; p_1^{[i]},
  &amp; p_2^{[i]},
  &amp; p_3^{[i]},
  &amp; \ldots,
  &amp; \delta(p_n)^{[i-1]} \\
\end{array}
$$</code></pre>
<p>Using this rewrite rule, we iteratively use $p^{[i]}$, $\delta(p)^{[i-1]}$, and $p^{[i-1]}$ to compute $\Delta(p)^{[i]}$. Then, we compute $\delta(p)^{[i]} = \Delta(p)^{[i]} - p^{[i]}$. We repeat this process until we reach a fixpoint. When we evaluate stratified Datalog programs with negation, we simply treat each negated predicate as if it were in the EDB. Moreover, if a rule is linear recursive, we can simplify the algorithm even further (see book for details).</p>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        skipTags: ['script', 'noscript', 'style', 'textarea'],
      },
      messageStyle: "none",
    });
  </script>
  </div>
</body>
</html>
